{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Models predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import product, combinations, permutations\n",
    "from importlib import reload\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Any, Dict, Tuple, Callable, Iterable, Union, Set\n",
    "Numeric = Union[int, float]\n",
    "from graph import Graph, Node     # mtool graphs\n",
    "import networkx as nx, numpy as np, pandas as pd\n",
    "from networkx import NetworkXNoPath\n",
    "\n",
    "# a hack for functional-like posfix list functions (map, filter, count, size)\n",
    "import gc\n",
    "postfix_map = lambda l,f: list(map(f,l))\n",
    "postfix_filter = lambda l,f: list(filter(f,l))\n",
    "postfix_count = lambda l,f: len(list(filter(f,l)))\n",
    "gc.get_referents(list.__dict__)[0]['map'] = postfix_map\n",
    "gc.get_referents(list.__dict__)[0]['filter'] = postfix_filter\n",
    "gc.get_referents(list.__dict__)[0]['count'] = postfix_count\n",
    "gc.get_referents(list.__dict__)[0]['size'] = lambda l:len(l)\n",
    "\n",
    "# root of project in nlp-architext repo\n",
    "libert_dir = \"/data/home/ayalklei/nlp-architect/nlp_architect/models/libert\"\n",
    "analysis_dir = f\"{libert_dir}/analysis\"\n",
    "\n",
    "# useful \"meta\" data - number of sentence per domain \n",
    "# (can be computed by #-lines in raw_sentences.txt files - `wc $liber_dir/analysis/raw_sentences/*.txt`)\n",
    "num_sents = {\"device\": 3834, \"restaurants\": 5842, \"laptops\": 3846}\n",
    "domains = list(num_sents.keys())\n",
    "ud_enhancement_formalisms = [\"eud\", \"eud_pp\", \"bart\", \"eud_pp_bart\"]\n",
    "# usefull general utils\n",
    "def display_table(table):\n",
    "    display(HTML(tabulate.tabulate(table, tablefmt='html')))\n",
    "\n",
    "def display_ndict(nested_dict: Dict[str, Dict[str, Any]], \n",
    "                  with_mean=True, \n",
    "                  pprint: Callable = None,\n",
    "                  precision: int = 4):\n",
    "    \"\"\" Display two-level nested dict as a pretty table. \"\"\"\n",
    "    if not pprint:\n",
    "        def pprint_f(x):\n",
    "            if isinstance(x, float):\n",
    "                return float(f\"{x:.{precision}f}\")\n",
    "            else:\n",
    "                return x\n",
    "        pprint = pprint_f\n",
    "    row_labels = list(nested_dict.keys())\n",
    "    column_labels = list(list(nested_dict.values())[0].keys())\n",
    "    as_tabular = [[\"-\"] + column_labels] + \\\n",
    "                 [[row] + [pprint(nested_dict[row][col]) for col in column_labels]\n",
    "                  for row in row_labels]\n",
    "    if with_mean:\n",
    "        as_tabular[0] += [\"mean\"]\n",
    "        for i in range(1, len(as_tabular)):\n",
    "            mean = np.mean(as_tabular[i][1:])\n",
    "            as_tabular[i] += [pprint(mean)]\n",
    "    display_table(as_tabular)\n",
    "\n",
    "def display_absa_graph(graph: Graph, method=\"displacy\"):\n",
    "    # visualize\n",
    "    print(f\"Sentence: {graph.input}\")\n",
    "    if method == \"dot\":\n",
    "        # visalize using dot\n",
    "        dot_fn = \"dot_example.dot\"\n",
    "        graph.dot(open(dot_fn, \"w\"))    # write dot file\n",
    "        # see dot in jupyter\n",
    "        def view_dot(fn):\n",
    "            from graphviz import Source\n",
    "            return Source.from_file(fn)\n",
    "        return view_dot(dot_fn)\n",
    "    elif method==\"tikz\":\n",
    "        # visalize using tikz\n",
    "        tikz_fn = \"tikz_example.tex\"\n",
    "        graph.tikz(open(tikz_fn, \"w\"))    # write tikz latex file\n",
    "        # I can't show it in notebook meantime since %load_ext tikzmagic not working\n",
    "        return None\n",
    "    else:\n",
    "        print(\"opinions: \", graph.opinion_spans, \n",
    "              [' '.join(graph.input.split(\" \")[i] \n",
    "                        for i in range(*span))\n",
    "                        for span in graph.opinion_spans])\n",
    "        print(\"aspects: \", graph.aspect_spans,\n",
    "              [' '.join(graph.input.split(\" \")[i] \n",
    "                        for i in range(*span))\n",
    "                        for span in graph.aspect_spans])\n",
    "        graph.displacy(jupyter=True, options={\"compact\":True, \"distance\":100})\n",
    "            \n",
    "def plot_hist_with_long_labels(array, bins=None, title=\"\"):\n",
    "    \"\"\" Display hostogram with rotated x-labels \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(array, bins = bins or len(array), color = 'blue', edgecolor = 'black',)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(270)\n",
    "    ax.set_title(title)\n",
    "\n",
    "def plot_bar_with_long_labels(labels, values, title=\"\"):\n",
    "    \"\"\" Display hostogram with rotated x-labels \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    indexes = np.arange(len(labels))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(indexes, values, color = 'blue', edgecolor = 'black')\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(270)\n",
    "    plt.xticks(indexes, labels)\n",
    "    ax.set_title(title)\n",
    "\n",
    "def plot_counter_with_long_labels(c: Counter):\n",
    "    plot_bar_with_long_labels(*zip(*c.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation utils\n",
    "def eval_p_r_f1(tp, fp, fn):\n",
    "    p = float(tp) / (tp + fp) if tp + fp > 0 else None\n",
    "    r = float(tp) / (tp + fn) if tp + fn > 0 else None\n",
    "    f1 = (2*p*r)/(p+r) if p and r else None\n",
    "    return p, r, f1\n",
    "def evaluate_sets(gold, predicted) -> Tuple[float, float, float]: # precision, recall, F1\n",
    "    tp = len(set(gold) & set(predicted))\n",
    "    fp = len(set(predicted) - set(gold))\n",
    "    fn = len(set(gold) - set(predicted))\n",
    "    return eval_p_r_f1(tp, fp, fn)\n",
    "def pretty_eval(p,r,f1):\n",
    "    return f\"P: {p:.2}   R: {r:.2}   F1: {f1:.2}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nblocks = \\n[[['great', 'B-OP', 'O'],\\n  ['taste', 'O', 'O']],\\n [['service', 'B-OP', 'B-ASP'],\\n  ['-', 'O', 'O'],\\n  ['friendly', 'B-OP', 'B-OP'],\\n  ['and', 'O', 'O'],\\n  ['attentive', 'B-OP', 'B-OP'],\\n  ['.', 'O', 'O']]\\n ...]\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which model\n",
    "exp_id = \"li-biafpatt-T10-L11_Fri_Jan_01_11:27:38\" # \"bert-amtl-AT_Mon_Dec_28_00:09:59\"\n",
    "formalism = \"dm\"\n",
    "exp_base_dir = f\"{libert_dir}/logs/{exp_id}/{formalism}\"\n",
    "\n",
    "src_domain, tgt_domain = \"laptops\", \"restaurants\"\n",
    "dataset = f\"{src_domain}_to_{tgt_domain}\"\n",
    "dataset_dir = f\"{exp_base_dir}/{dataset}\"\n",
    "predictions_fn = f\"{dataset_dir}/prediction-test.txt\"\n",
    "\n",
    "with open(predictions_fn) as fin:\n",
    "    blocks = [[line.split(\"\\t\") for line in block.split(\"\\n\")] \n",
    "              for block in fin.read().strip().split(\"\\n\\n\")]\n",
    "\"\"\"\n",
    "blocks = \n",
    "[[['great', 'B-OP', 'O'],\n",
    "  ['taste', 'O', 'O']],\n",
    " [['service', 'B-OP', 'B-ASP'],\n",
    "  ['-', 'O', 'O'],\n",
    "  ['friendly', 'B-OP', 'B-OP'],\n",
    "  ['and', 'O', 'O'],\n",
    "  ['attentive', 'B-OP', 'B-OP'],\n",
    "  ['.', 'O', 'O']]\n",
    " ...]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OP:  1136 TPs,  463 FPs,  463 FNs;\t P: 0.71   R: 0.71   F1: 0.71\n",
      "ASP: 83 TPs,  44 FPs,  2110 FNs;\t P: 0.65   R: 0.038   F1: 0.072\n"
     ]
    }
   ],
   "source": [
    "TPs, FPs, FNs = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "for sent in blocks:\n",
    "    tokens, pred_lbls, gold_lbls = zip(*sent)\n",
    "    sent_str = ' '.join(tokens)\n",
    "    # compute TP,FP,FN in token level - ignore B\\I difference\n",
    "    def lbl(bio_tag):\n",
    "        return bio_tag.split(\"-\")[1] if \"-\" in bio_tag else \"O\"\n",
    "    for i, (pred, gold) in enumerate(zip(pred_lbls, gold_lbls)):\n",
    "        pred, gold = lbl(pred), lbl(gold)\n",
    "        if pred==gold and gold != \"O\":\n",
    "            TPs[gold].append((sent_str, i))\n",
    "        elif pred!=gold:\n",
    "            if gold != \"O\":\n",
    "                FNs[gold].append((sent_str, i))\n",
    "            if pred != \"O\":\n",
    "                FPs[pred].append((sent_str, i))\n",
    "print(f'OP:  {len(TPs[\"OP\"])} TPs,  {len(FPs[\"OP\"])} FPs,  {len(FNs[\"OP\"])} FNs;\\t {pretty_eval(*eval_p_r_f1(len(TPs[\"OP\"]), len(FPs[\"OP\"]), len(FNs[\"OP\"])))}')\n",
    "print(f'ASP: {len(TPs[\"ASP\"])} TPs,  {len(FPs[\"ASP\"])} FPs,  {len(FNs[\"ASP\"])} FNs;\\t {pretty_eval(*eval_p_r_f1(len(TPs[\"ASP\"]), len(FPs[\"ASP\"]), len(FNs[\"ASP\"])))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libert_ud",
   "language": "python",
   "name": "libert_ud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
